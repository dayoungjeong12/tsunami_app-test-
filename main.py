import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

# -----------------------------------------------------------------------------
# 1. ì•± ì„¤ì • ë° ì œëª©
# -----------------------------------------------------------------------------
st.set_page_config(page_title="ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ", page_icon="ğŸŒŠ")

st.title("ğŸŒŠ ì§€ì§„ ë°œìƒ ì‹œ ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
st.markdown("""
ì´ ì•±ì€ ì§€ì§„ ë°ì´í„°ë¥¼ í•™ìŠµí•œ **Random Forest ëª¨ë¸**ì„ ì‚¬ìš©í•˜ì—¬, 
ì…ë ¥ëœ ì§€ì§„ ì •ë³´(ê·œëª¨, ê¹Šì´, ìœ„ì¹˜)ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì“°ë‚˜ë¯¸ ë°œìƒ ê°€ëŠ¥ì„±**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
""")

# -----------------------------------------------------------------------------
# 2. í•œê¸€ í°íŠ¸ ì„¤ì • (â­ìˆ˜ì •ëœ ë¶€ë¶„: koreanize_matplotlib ëŒ€ì‹  ì§ì ‘ ì„¤ì •â­)
# Streamlit Cloud í™˜ê²½ì—ì„œ Matplotlib í•œê¸€ ê¹¨ì§ì„ ë°©ì§€í•©ë‹ˆë‹¤.
# -----------------------------------------------------------------------------
try:
    # Streamlit Cloudì—ì„œ NanumGothicì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    plt.rcParams['font.family'] = 'NanumGothic'
except:
    # NanumGothicì´ ì—†ì„ ê²½ìš° fallback
    plt.rcParams['font.family'] = 'sans-serif' 
    st.warning("ê²½ê³ : Streamlit Cloud í™˜ê²½ì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# -----------------------------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ (ìºì‹± ê¸°ëŠ¥ ì‚¬ìš©)
# -----------------------------------------------------------------------------
@st.cache_data
def load_data():
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (íŒŒì¼ ê²½ë¡œê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •)
    try:
        df = pd.read_csv("earthquake_data_tsunami.csv")
    except FileNotFoundError:
        st.error("âŒ 'earthquake_data_tsunami.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    return df

@st.cache_resource
def train_model(df):
    # í•„ìš”í•œ ì—´ ì„ íƒ
    X = df[["magnitude", "depth", "latitude", "longitude"]]
    y = df["tsunami"]
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # ëª¨ë¸ í•™ìŠµ
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # ì •í™•ë„ í‰ê°€
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    
    return model, acc, X.columns.tolist()

# ë°ì´í„° ë¡œë“œ ë° í•™ìŠµ ì‹¤í–‰
df = load_data()
model, accuracy, feature_names = train_model(df)
st.success(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ëª¨ë¸ ì •í™•ë„: {accuracy:.2f})")

st.divider()

# -----------------------------------------------------------------------------
# 4. ì‚¬ì´ë“œë°”: ì‚¬ìš©ì ì…ë ¥ (ìŠ¬ë¼ì´ë”)
# -----------------------------------------------------------------------------
st.sidebar.header("ğŸŒ ì§€ì§„ ì •ë³´ ì…ë ¥")
st.sidebar.write("ì§€ì§„ ì •ë³´ë¥¼ ìŠ¬ë¼ì´ë”ë¡œ ì¡°ì ˆí•˜ì„¸ìš”.")

# ë°ì´í„°í”„ë ˆì„ì˜ min/max ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¬ë¼ì´ë” ë²”ìœ„ ì„¤ì •
magnitude_min, magnitude_max = df['magnitude'].min(), df['magnitude'].max()
depth_min, depth_max = df['depth'].min(), df['depth'].max()
latitude_min, latitude_max = df['latitude'].min(), df['latitude'].max()
longitude_min, longitude_max = df['longitude'].min(), df['longitude'].max()

# ìŠ¬ë¼ì´ë” ì„¤ì •
magnitude = st.sidebar.slider("ì§€ì§„ ê·œëª¨ (Magnitude)", 
                              min_value=magnitude_min, max_value=magnitude_max, 
                              value=min(6.0, magnitude_max), step=0.1)
depth = st.sidebar.slider("ê¹Šì´ (Depth, km)", 
                          min_value=int(depth_min), max_value=int(depth_max), 
                          value=min(50, int(depth_max)), step=1)
latitude = st.sidebar.slider("ìœ„ë„ (Latitude)", 
                             min_value=latitude_min, max_value=latitude_max, 
                             value=np.mean([latitude_min, latitude_max]), step=0.1)
longitude = st.sidebar.slider("ê²½ë„ (Longitude)", 
                              min_value=longitude_min, max_value=longitude_max, 
                              value=np.mean([longitude_min, longitude_max]), step=0.1)

# ì…ë ¥ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
input_data = pd.DataFrame({
    'magnitude': [magnitude],
    'depth': [depth],
    'latitude': [latitude],
    'longitude': [longitude]
})

# -----------------------------------------------------------------------------
# 5. ë©”ì¸ í™”ë©´: ì˜ˆì¸¡ ë° ì‹œê°í™”
# -----------------------------------------------------------------------------

# 5-1. ì…ë ¥ ìœ„ì¹˜ ì§€ë„ í‘œì‹œ
st.subheader("ğŸ“ ì§€ì§„ ë°œìƒ ìœ„ì¹˜")
st.map(input_data)

# 5-2. ì˜ˆì¸¡í•˜ê¸° ë²„íŠ¼ ë° ê²°ê³¼ ì¶œë ¥
if st.button("ğŸš¨ ì“°ë‚˜ë¯¸ ë°œìƒ ì˜ˆì¸¡í•˜ê¸°", type="primary"):
    with st.spinner('ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤...'):
        prediction = model.predict(input_data)[0]
        # ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥  (í´ë˜ìŠ¤ 1)
        probability = model.predict_proba(input_data)[0][1] 

    st.subheader("ì˜ˆì¸¡ ê²°ê³¼")
    
    if prediction == 1:
        st.error(f"âš ï¸ **ê²½ê³ : ì“°ë‚˜ë¯¸ ë°œìƒ ìœ„í—˜ì´ ë†’ìŠµë‹ˆë‹¤!** (í™•ë¥ : {probability*100:.1f}%)")
        st.write("ì¦‰ì‹œ ëŒ€í”¼ ì •ë³´ë¥¼ í™•ì¸í•˜ê³  ì•ˆì „í•œ ê³³ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
    else:
        st.success(f"âœ… **ì•ˆì „: ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤.** (í™•ë¥ : {probability*100:.1f}%)")
        st.write("ì§€ì§„ í”¼í•´ ìƒí™©ì„ ì£¼ì‹œí•˜ì„¸ìš”.")

# 5-3. ì¤‘ìš” ë³€ìˆ˜ ì‹œê°í™”
with st.expander("ğŸ“Š ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” íŠ¹ì„± ë³´ê¸°"):
    fig, ax = plt.subplots()
    importances = model.feature_importances_
    
    # í•œê¸€ ì œëª©/ë¼ë²¨ ì ìš©
    ax.bar(feature_names, importances, color='skyblue')
    ax.set_title("Feature Importance (íŠ¹ì„±ì´ ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥)")
    ax.set_ylabel("ì¤‘ìš”ë„")
    
    st.pyplot(fig)
