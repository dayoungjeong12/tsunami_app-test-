import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

# -----------------------------------------------------------------------------
# 1. ì•± ì„¤ì • ë° ì œëª©
# -----------------------------------------------------------------------------
st.set_page_config(page_title="ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ", page_icon="ğŸŒŠ")

st.title("ğŸŒŠ ì§€ì§„ ë°œìƒ ì‹œ ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
st.markdown("""
ì…ë ¥ëœ ì§€ì§„ ì •ë³´(ê·œëª¨, ê¹Šì´, ìœ„ì¹˜)ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì“°ë‚˜ë¯¸ ë°œìƒ ê°€ëŠ¥ì„±**ì„ ì˜ˆì¸¡í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì§€ì§„ ì •ë³´ë¥¼ ì¡°ì ˆí•˜ê³  ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.
""")

# -----------------------------------------------------------------------------
# 2. í•œê¸€ í°íŠ¸ ì„¤ì •
# ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ koreanize_matplotlib ëŒ€ì‹  ì§ì ‘ Matplotlib í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
# -----------------------------------------------------------------------------
try:
    # Streamlit Cloud í™˜ê²½ì—ì„œ NanumGothicì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    plt.rcParams['font.family'] = 'NanumGothic'
except:
    # NanumGothicì´ ì—†ì„ ê²½ìš° fallback
    plt.rcParams['font.family'] = 'sans-serif' 
    st.warning("ê²½ê³ : Matplotlib ì°¨íŠ¸ì˜ í•œê¸€ í°íŠ¸ ì„¤ì •ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# -----------------------------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ (ìºì‹± ê¸°ëŠ¥ ì‚¬ìš©)
# -----------------------------------------------------------------------------
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("earthquake_data_tsunami.csv")
    except FileNotFoundError:
        st.error("âŒ 'earthquake_data_tsunami.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    return df

@st.cache_resource
def train_model(df):
    X = df[["magnitude", "depth", "latitude", "longitude"]]
    y = df["tsunami"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # ëª¨ë¸ í•™ìŠµ: Random Forest Classifier ì‚¬ìš©
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    
    return model, acc, X.columns.tolist()

# ë°ì´í„° ë¡œë“œ ë° í•™ìŠµ ì‹¤í–‰
df = load_data()
model, accuracy, feature_names = train_model(df)
st.success(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„: {accuracy:.2f})")

st.divider()

# -----------------------------------------------------------------------------
# 4. ì‚¬ì´ë“œë°”: ì‚¬ìš©ì ì…ë ¥ (ìŠ¬ë¼ì´ë”)
# -----------------------------------------------------------------------------
st.sidebar.header("ğŸŒ ì§€ì§„ ì •ë³´ ì…ë ¥")
st.sidebar.write("ì§€ì§„ ì •ë³´ë¥¼ ìŠ¬ë¼ì´ë”ë¡œ ì¡°ì ˆí•˜ì—¬ ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.")

# ë°ì´í„°í”„ë ˆì„ì˜ min/max ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¬ë¼ì´ë” ë²”ìœ„ ì„¤ì •
magnitude_min, magnitude_max = df['magnitude'].min(), df['magnitude'].max()
depth_min, depth_max = df['depth'].min(), df['depth'].max()
latitude_min, latitude_max = df['latitude'].min(), df['latitude'].max()
longitude_min, longitude_max = df['longitude'].min(), df['longitude'].max()

# ìŠ¬ë¼ì´ë” ì„¤ì •
magnitude = st.sidebar.slider("ì§€ì§„ ê·œëª¨ (Magnitude)", 
                              min_value=magnitude_min, max_value=magnitude_max, 
                              value=min(6.5, magnitude_max), step=0.1)
depth = st.sidebar.slider("ê¹Šì´ (Depth, km)", 
                          min_value=int(depth_min), max_value=int(depth_max), 
                          value=min(30, int(depth_max)), step=1)
latitude = st.sidebar.slider("ìœ„ë„ (Latitude)", 
                             min_value=latitude_min, max_value=latitude_max, 
                             value=np.mean([latitude_min, latitude_max]), step=0.1)
longitude = st.sidebar.slider("ê²½ë„ (Longitude)", 
                              min_value=longitude_min, max_value=longitude_max, 
                              value=np.mean([longitude_min, longitude_max]), step=0.1)

# ì…ë ¥ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
input_data = pd.DataFrame({
    'magnitude': [magnitude],
    'depth': [depth],
    'latitude': [latitude],
    'longitude': [longitude]
})

# -----------------------------------------------------------------------------
# 5. ë©”ì¸ í™”ë©´: ì˜ˆì¸¡ ë° ê²°ê³¼ ì¶œë ¥
# -----------------------------------------------------------------------------

st.subheader("ğŸ“ ì§€ì§„ ë°œìƒ ìœ„ì¹˜")
st.map(input_data)

if st.button("ğŸš¨ ì“°ë‚˜ë¯¸ ë°œìƒ ì˜ˆì¸¡í•˜ê¸°", type="primary"):
    with st.spinner('ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤...'):
        prediction = model.predict(input_data)[0]
        # ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥  (í´ë˜ìŠ¤ 1)
        probability = model.predict_proba(input_data)[0][1] 

    st.subheader("ì˜ˆì¸¡ ê²°ê³¼")
    
    if prediction == 1:
        st.error(f"âš ï¸ **ê²½ê³ : ì“°ë‚˜ë¯¸ ë°œìƒ ìœ„í—˜ì´ ë†’ìŠµë‹ˆë‹¤!** (í™•ë¥ : {probability*100:.1f}%)")
        st.write("ì“°ë‚˜ë¯¸ ë°œìƒì´ ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ **ëŒ€ì‘ì±…**ì„ í™•ì¸í•˜ê³  ì¦‰ì‹œ ëŒ€í”¼í•˜ì„¸ìš”!")
    else:
        st.success(f"âœ… **ì•ˆì „: ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤.** (í™•ë¥ : {probability*100:.1f}%)")
        st.write("ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥ ì€ ë‚®ì§€ë§Œ, ì§€ì§„ ë°œìƒ ì‹œì—ëŠ” í•­ìƒ ì£¼ì˜í•˜ê³  ì¬ë‚œ ë°©ì†¡ì— ê·€ ê¸°ìš¸ì—¬ì•¼ í•©ë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 6. ëª¨ë¸ ì„¤ëª… ë° ëŒ€ì‘ì±… ì„¹ì…˜ ì¶”ê°€ (ì‚¬ìš©ì ìš”ì²­ ì‚¬í•­)
# -----------------------------------------------------------------------------

st.divider()

## ğŸ› ï¸ ëª¨ë¸ ë¶„ì„ ë° ì„¤ëª…

with st.expander("ëª¨ë¸ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ ë³´ê¸°"):
    st.markdown(
        """
        ### ì‚¬ìš© ëª¨ë¸: Random Forest Classifier (ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°)
        
        **Random Forest**ëŠ” ì—¬ëŸ¬ ê°œì˜ **ê²°ì • íŠ¸ë¦¬(Decision Tree)**ë¥¼ ë§Œë“¤ê³ , 
        ê·¸ ê²°ì • íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ëª¨ì•„ ë‹¤ìˆ˜ê²°ë¡œ ìµœì¢… ì˜ˆì¸¡ì„ ê²°ì •í•˜ëŠ” **ì•™ìƒë¸”(Ensemble) í•™ìŠµ** ê¸°ë²•ì…ë‹ˆë‹¤.
        
        #### íŠ¹ì§•
        * **ë†’ì€ ì •í™•ë„**: ë‹¤ì–‘í•œ íŠ¸ë¦¬ì˜ ì˜ê²¬ì„ ì¢…í•©í•˜ê¸° ë•Œë¬¸ì— ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ì •í™•ë„ê°€ ë†’ìŠµë‹ˆë‹¤.
        * **ê³¼ì í•©(Overfitting) ë°©ì§€**: ì—¬ëŸ¬ ë¬´ì‘ìœ„ í‘œë³¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ë°ì´í„°ì— ì§€ë‚˜ì¹˜ê²Œ ë§ì¶°ì§€ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
        * **ë³€ìˆ˜ ì¤‘ìš”ë„ ì œê³µ**: ê° íŠ¹ì„±(ê·œëª¨, ê¹Šì´ ë“±)ì´ ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
    )
    
    # ì¤‘ìš” ë³€ìˆ˜ ì‹œê°í™”
    fig, ax = plt.subplots()
    importances = model.feature_importances_
    ax.bar(feature_names, importances, color='skyblue')
    ax.set_title("Feature Importance (íŠ¹ì„±ì´ ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥)")
    ax.set_ylabel("ì¤‘ìš”ë„")
    st.pyplot(fig)


## ğŸš¨ ì“°ë‚˜ë¯¸ ë°œìƒ ì‹œ ëŒ€ì‘ì±…

with st.expander("ì“°ë‚˜ë¯¸ ë°œìƒ ì‹œ í–‰ë™ ìš”ë ¹"):
    st.markdown(
        """
        ### ğŸŒŠ ì“°ë‚˜ë¯¸ ê²½ë³´ ì‹œ ì¦‰ê°ì ì¸ ëŒ€í”¼ ìš”ë ¹
        
        ì“°ë‚˜ë¯¸ëŠ” ì§€ì§„ì´ ë°œìƒí•œ í›„ ìˆ˜ë¶„ì—ì„œ ìˆ˜ì‹œê°„ ë‚´ì— í•´ì•ˆì— ë„ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        1.  **ì¦‰ì‹œ ëŒ€í”¼**: ì§€ì§„ ë°œìƒ í›„ í•´ì•ˆê°€ì— ìˆë‹¤ë©´, ì§€ì§„ì˜ ê·œëª¨ë‚˜ ê³µì‹ì ì¸ ê²½ë³´ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ì¦‰ì‹œ ê°€ì¥ ë†’ì€ ê³³ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.
        2.  **ë†’ì€ ê³³ìœ¼ë¡œ**: í•´ì•ˆì—ì„œ ë©€ë¦¬ ë–¨ì–´ì§„ **ê³ ì§€ëŒ€**ë‚˜ íŠ¼íŠ¼í•œ **ë†’ì€ ê±´ë¬¼ 3ì¸µ ì´ìƒ**ìœ¼ë¡œ ëŒ€í”¼í•©ë‹ˆë‹¤.
        3.  **ì´ë™ ìˆ˜ë‹¨**: ì°¨ëŸ‰ ì •ì²´ë¡œ ëŒ€í”¼ê°€ ëŠ¦ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í•œ **ë„ë³´**ë¡œ ëŒ€í”¼í•©ë‹ˆë‹¤.
        4.  **ì •ë³´ ê²½ì²­**: ì •ë¶€, ì–¸ë¡ , ì¬ë‚œ ë°©ì†¡ ë“±ì„ í†µí•´ ê³µì‹ì ì¸ ì“°ë‚˜ë¯¸ ì •ë³´ë¥¼ ì§€ì†ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
        5.  **ê²½ë³´ í•´ì œê¹Œì§€**: ì“°ë‚˜ë¯¸ëŠ” í•œ ë²ˆìœ¼ë¡œ ëë‚˜ì§€ ì•Šê³  ì—¬ëŸ¬ ì°¨ë¡€ ë°˜ë³µë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, **ê²½ë³´ê°€ ê³µì‹ì ìœ¼ë¡œ í•´ì œë  ë•Œê¹Œì§€** í•´ì•ˆê°€ë¡œ ëŒì•„ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
    )
